# ğŸ” Natural Language Image & Video Search Engine (VLM API-Based)

## ğŸ“Œ Project Overview

This project enables **natural language search over local images and videos** using **Vision-Language Models (VLMs)** such as OpenAI's GPT-4o or Gemini API. It supports:

- Image/video upload and indexing
- Semantic vector search powered by VLM API
- Search results returned by relevance
- Album / category based filtering (granularity-aware search)

Backend is implemented in **Python using FastAPI**, with potential future migration to **local inference (e.g. vLLM or OpenVINO)** via modular abstraction. Frontend is prototyped using **Streamlit** for quick iteration and testing.

---

## ğŸ›  Tech Stack

| Component  | Technology                         |
| ---------- | ---------------------------------- |
| Backend    | Python + FastAPI                   |
| Frontend   | Python + Streamlit (temporary UI)  |
| Vector DB  | FAISS + SQLite (or pgvector later) |
| Model API  | OpenAI GPT-4o (via `openai` lib)   |
| Deployment | Docker + `.env` config             |

---

## ğŸ“ Folder Structure

```
vlm-search/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py          # FastAPI route definitions
â”‚   â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ embedding.py       # OpenAI or vLLM embedding wrapper
â”‚   â”‚   â””â”€â”€ search.py          # FAISS vector search logic
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ storage.py         # SQLite or PostgreSQL metadata handler
â”‚   â””â”€â”€ main.py                # FastAPI app entry point
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                 # Streamlit UI interface
â”œâ”€â”€ data/
â”‚   â””â”€â”€ media/                 # Uploaded images/videos
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.template
â””â”€â”€ README.md
```

---

## ğŸ”§ Setup Instructions

### 1. Clone & Install

```bash
git clone https://github.com/kevinzhao-dev/nlSearch.git
cd vlm-search
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 2. Configure Environment

Copy the template and fill in your keys:

```bash
cp .env.template .env
```

`.env.template`

```env
OPENAI_API_KEY=sk-xxx
EMBEDDING_MODEL=text-embedding-3-small
VLM_MODEL=gpt-4o
```

### 3. Launch Backend

```bash
uvicorn backend.main:app --reload
```

### 4. Launch Frontend (Prototype)

```bash
streamlit run frontend/app.py
```

---

## ğŸ“¦ API Design

### ğŸ”¹ `/embed/text`

```http
POST /embed/text
{
  "text": "A man walking a dog in the park"
}
â†’ Returns embedding vector
```

### ğŸ”¹ `/embed/image`

```http
POST /embed/image
FormData: image file
â†’ Returns embedding vector
```

### ğŸ”¹ `/index`

```http
POST /index
{
  "media_id": "IMG001",
  "vector": [...],
  "metadata": {
    "album": "vacation",
    "tags": ["beach", "sunset"]
  }
}
â†’ Stores in FAISS and DB
```

### ğŸ”¹ `/search`

```http
POST /search
{
  "query": "sunset on the beach",
  "album": "vacation"
}
â†’ Returns list of similar images
```

---

## ğŸ”„ Swappable Inference Layer

Backend uses `services/embedding.py` as abstraction:

```python
# backend/services/embedding.py

def embed_text(text: str) -> List[float]:
    # Call OpenAI GPT-4o or replace with local vLLM
    ...

def embed_image(image_bytes: bytes) -> List[float]:
    # VLM-based visual embedding (OpenAI or future local)
    ...
```

To switch to local inference (e.g. vLLM or CLIP+BLIP):

- Replace this module only.
- Maintain same input/output interface.

---

## ğŸ§ª `requirements.txt`

```txt
fastapi
uvicorn
python-dotenv
openai
streamlit
faiss-cpu
pydantic
pillow
```

---

## ğŸ³ `Dockerfile`

```dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY . /app

RUN pip install --upgrade pip && \
    pip install -r requirements.txt

CMD ["uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ“Œ Future Extensions

- Switch backend to `vLLM` or `Gemma` for offline inference
- Add video summarization & keyframe embedding
- Enable Q\&A over video scenes (multimodal reasoning)
- Multi-user support with auth & cloud sync

---

## ğŸ¤ Contributions

Interns should write clean code with type hints and docstrings. PRs should include:

- New tests or sample scripts
- Description of what was changed and why
